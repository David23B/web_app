{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "train = pd.read_csv('./train_10000.csv')\n",
    "valid_auth = pd.read_csv('validate_1000.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 绘图代码，可随时调用，用于查看数据预处理效果"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# 将训练集的所有数据绘制散点图，存储在train\n",
    "import matplotlib.pyplot as plt\n",
    "for feature in range(1,107):\n",
    "    train_label_0 = train.loc[train['label'] == 0]\n",
    "    train_label_1 = train.loc[train['label'] == 1]\n",
    "    train_label_2 = train.loc[train['label'] == 2]\n",
    "    train_label_3 = train.loc[train['label'] == 3]\n",
    "    train_label_4 = train.loc[train['label'] == 4]\n",
    "    train_label_5 = train.loc[train['label'] == 5]\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)\n",
    "    plt.scatter(train_label_0['sample_id'],train_label_0.iloc[:,[feature]],s=0.2,c='blue', facecolor='grey')\n",
    "    plt.scatter(train_label_1['sample_id'],train_label_1.iloc[:,[feature]],s=0.2,c='black', facecolor='grey')\n",
    "    plt.scatter(train_label_2['sample_id'],train_label_2.iloc[:,[feature]],s=0.2,c='green', facecolor='grey')\n",
    "    plt.scatter(train_label_3['sample_id'],train_label_3.iloc[:,[feature]],s=0.2,c='red', facecolor='grey')\n",
    "    plt.scatter(train_label_4['sample_id'],train_label_4.iloc[:,[feature]],s=0.2,c='orange', facecolor='grey')\n",
    "    plt.scatter(train_label_5['sample_id'],train_label_5.iloc[:,[feature]],s=0.2,c='purple', facecolor='grey')\n",
    "    plt.savefig(f'imputed_train/{feature-1}.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 将验证集的所有数据绘制散点图，存储在validation文件夹\n",
    "import matplotlib.pyplot as plt\n",
    "for feature in range(1,107):\n",
    "    valid_label_0 = valid_auth.loc[valid_auth['label'] == 0]\n",
    "    valid_label_1 = valid_auth.loc[valid_auth['label'] == 1]\n",
    "    valid_label_2 = valid_auth.loc[valid_auth['label'] == 2]\n",
    "    valid_label_3 = valid_auth.loc[valid_auth['label'] == 3]\n",
    "    valid_label_4 = valid_auth.loc[valid_auth['label'] == 4]\n",
    "    valid_label_5 = valid_auth.loc[valid_auth['label'] == 5]\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)\n",
    "    plt.scatter(valid_label_0['sample_id'],valid_label_0.iloc[:,[feature]],s=2,c='blue', facecolor='grey')\n",
    "    plt.scatter(valid_label_1['sample_id'],valid_label_1.iloc[:,[feature]],s=2,c='black', facecolor='grey')\n",
    "    plt.scatter(valid_label_2['sample_id'],valid_label_2.iloc[:,[feature]],s=2,c='green', facecolor='grey')\n",
    "    plt.scatter(valid_label_3['sample_id'],valid_label_3.iloc[:,[feature]],s=2,c='red', facecolor='grey')\n",
    "    plt.scatter(valid_label_4['sample_id'],valid_label_4.iloc[:,[feature]],s=2,c='orange', facecolor='grey')\n",
    "    plt.scatter(valid_label_5['sample_id'],valid_label_5.iloc[:,[feature]],s=2,c='purple', facecolor='grey')\n",
    "    # plt.scatter(valid_auth['sample_id'],valid_auth.iloc[:,[feature]],s=0.2,c='red')\n",
    "    plt.savefig(f'validation/{feature-1}.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 使用四分位点判别法，对训练集的label==0和label==1的值进行降噪处理，然后采用KNN填充缺失值。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这是第一种四分位判别法，基于label==0和label==1来确定离群值的阈值，然后应用这些阈值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "      sample_id   feature0  feature1  feature2  feature3    feature4  \\\n0             0  51.567250  288358.4       NaN  1.855900  201.460169   \n1             1  63.804874  288358.4  1.106802  1.050387  391.605375   \n2             2  49.138527  288358.4  1.111649  0.767127  130.708067   \n3             3        NaN  288358.4  1.109169       NaN  258.521076   \n4             4  76.520831  288358.4  1.113410  5.795408  256.038997   \n...         ...        ...       ...       ...       ...         ...   \n9995       9995  66.948837  288358.4  1.102805       NaN  260.805938   \n9996       9996        NaN  288358.4  1.107632  0.679847         NaN   \n9997       9997  42.208350  288358.4  1.110253  0.037611  180.875482   \n9998       9998  26.797447  288358.4  1.094471  0.505019  253.278224   \n9999       9999  63.908598  288358.4       NaN  0.803881  234.035162   \n\n       feature5   feature6      feature7      feature8  ...      feature98  \\\n0      6.582261  -0.516321  5.636771e+11  2.222212e+05  ...   31459.628135   \n1     13.323439   4.662871           NaN -1.442474e+05  ...   42830.526855   \n2      6.485547   5.696815  5.474603e+11 -4.288403e+05  ...  249963.241809   \n3      0.716737  23.238461 -3.539891e+11           NaN  ...  125478.297201   \n4     -1.803483  14.040495 -1.071014e+11  6.499723e+05  ...  186266.423019   \n...         ...        ...           ...           ...  ...            ...   \n9995   6.663322  -6.495112 -1.959797e+11 -1.169449e+06  ...  131837.380427   \n9996  22.327405   2.251901  8.157356e+11  1.887989e+05  ...    3416.075865   \n9997   9.471924   6.725166  1.039534e+12  8.453963e+04  ...            NaN   \n9998  19.199080  -4.451117  5.994078e+11 -3.025228e+05  ...  101045.903091   \n9999  16.398958  -2.217535  4.389648e+11  8.104504e+05  ...   78226.955793   \n\n       feature99  feature100    feature101  feature102  feature103  \\\n0     254.582034         0.0 -2.014506e+08  159.299350    0.603211   \n1     270.580779         0.0 -1.534970e+09         NaN    0.506220   \n2     160.207067         0.0  7.998345e+08  112.632639    0.080100   \n3     196.223295         0.0 -9.246920e+07  138.431470    2.548783   \n4     179.083883         0.0 -6.796351e+08  259.858740    0.337643   \n...          ...         ...           ...         ...         ...   \n9995  207.050530         0.0 -5.375408e+08         NaN    1.598658   \n9996  228.252191         0.0  4.302888e+08         NaN    2.348464   \n9997  211.716051         0.0 -5.853507e+07  167.836714    3.840799   \n9998  225.324419         0.0  7.009934e+08   27.189454    0.538561   \n9999  157.853686         0.0 -8.710744e+07  252.716160         NaN   \n\n      feature104  feature105  feature106  label  \n0            NaN   -5.256075  180.977310      4  \n1       0.552654   16.505952  314.783263      5  \n2       0.235920   64.707581  183.304610      2  \n3       1.414810   -9.662399  212.302670      2  \n4       0.228832   59.733069  135.541233      2  \n...          ...         ...         ...    ...  \n9995    1.239977   -1.625234         NaN      0  \n9996    3.079268   11.018358  250.312228      0  \n9997         NaN   75.537477  241.702576      2  \n9998         NaN  -10.481948  113.104089      0  \n9999         NaN   -3.776887  101.844761      0  \n\n[10000 rows x 109 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>feature0</th>\n      <th>feature1</th>\n      <th>feature2</th>\n      <th>feature3</th>\n      <th>feature4</th>\n      <th>feature5</th>\n      <th>feature6</th>\n      <th>feature7</th>\n      <th>feature8</th>\n      <th>...</th>\n      <th>feature98</th>\n      <th>feature99</th>\n      <th>feature100</th>\n      <th>feature101</th>\n      <th>feature102</th>\n      <th>feature103</th>\n      <th>feature104</th>\n      <th>feature105</th>\n      <th>feature106</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>51.567250</td>\n      <td>288358.4</td>\n      <td>NaN</td>\n      <td>1.855900</td>\n      <td>201.460169</td>\n      <td>6.582261</td>\n      <td>-0.516321</td>\n      <td>5.636771e+11</td>\n      <td>2.222212e+05</td>\n      <td>...</td>\n      <td>31459.628135</td>\n      <td>254.582034</td>\n      <td>0.0</td>\n      <td>-2.014506e+08</td>\n      <td>159.299350</td>\n      <td>0.603211</td>\n      <td>NaN</td>\n      <td>-5.256075</td>\n      <td>180.977310</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>63.804874</td>\n      <td>288358.4</td>\n      <td>1.106802</td>\n      <td>1.050387</td>\n      <td>391.605375</td>\n      <td>13.323439</td>\n      <td>4.662871</td>\n      <td>NaN</td>\n      <td>-1.442474e+05</td>\n      <td>...</td>\n      <td>42830.526855</td>\n      <td>270.580779</td>\n      <td>0.0</td>\n      <td>-1.534970e+09</td>\n      <td>NaN</td>\n      <td>0.506220</td>\n      <td>0.552654</td>\n      <td>16.505952</td>\n      <td>314.783263</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>49.138527</td>\n      <td>288358.4</td>\n      <td>1.111649</td>\n      <td>0.767127</td>\n      <td>130.708067</td>\n      <td>6.485547</td>\n      <td>5.696815</td>\n      <td>5.474603e+11</td>\n      <td>-4.288403e+05</td>\n      <td>...</td>\n      <td>249963.241809</td>\n      <td>160.207067</td>\n      <td>0.0</td>\n      <td>7.998345e+08</td>\n      <td>112.632639</td>\n      <td>0.080100</td>\n      <td>0.235920</td>\n      <td>64.707581</td>\n      <td>183.304610</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>288358.4</td>\n      <td>1.109169</td>\n      <td>NaN</td>\n      <td>258.521076</td>\n      <td>0.716737</td>\n      <td>23.238461</td>\n      <td>-3.539891e+11</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>125478.297201</td>\n      <td>196.223295</td>\n      <td>0.0</td>\n      <td>-9.246920e+07</td>\n      <td>138.431470</td>\n      <td>2.548783</td>\n      <td>1.414810</td>\n      <td>-9.662399</td>\n      <td>212.302670</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>76.520831</td>\n      <td>288358.4</td>\n      <td>1.113410</td>\n      <td>5.795408</td>\n      <td>256.038997</td>\n      <td>-1.803483</td>\n      <td>14.040495</td>\n      <td>-1.071014e+11</td>\n      <td>6.499723e+05</td>\n      <td>...</td>\n      <td>186266.423019</td>\n      <td>179.083883</td>\n      <td>0.0</td>\n      <td>-6.796351e+08</td>\n      <td>259.858740</td>\n      <td>0.337643</td>\n      <td>0.228832</td>\n      <td>59.733069</td>\n      <td>135.541233</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9995</td>\n      <td>66.948837</td>\n      <td>288358.4</td>\n      <td>1.102805</td>\n      <td>NaN</td>\n      <td>260.805938</td>\n      <td>6.663322</td>\n      <td>-6.495112</td>\n      <td>-1.959797e+11</td>\n      <td>-1.169449e+06</td>\n      <td>...</td>\n      <td>131837.380427</td>\n      <td>207.050530</td>\n      <td>0.0</td>\n      <td>-5.375408e+08</td>\n      <td>NaN</td>\n      <td>1.598658</td>\n      <td>1.239977</td>\n      <td>-1.625234</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9996</td>\n      <td>NaN</td>\n      <td>288358.4</td>\n      <td>1.107632</td>\n      <td>0.679847</td>\n      <td>NaN</td>\n      <td>22.327405</td>\n      <td>2.251901</td>\n      <td>8.157356e+11</td>\n      <td>1.887989e+05</td>\n      <td>...</td>\n      <td>3416.075865</td>\n      <td>228.252191</td>\n      <td>0.0</td>\n      <td>4.302888e+08</td>\n      <td>NaN</td>\n      <td>2.348464</td>\n      <td>3.079268</td>\n      <td>11.018358</td>\n      <td>250.312228</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9997</td>\n      <td>42.208350</td>\n      <td>288358.4</td>\n      <td>1.110253</td>\n      <td>0.037611</td>\n      <td>180.875482</td>\n      <td>9.471924</td>\n      <td>6.725166</td>\n      <td>1.039534e+12</td>\n      <td>8.453963e+04</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>211.716051</td>\n      <td>0.0</td>\n      <td>-5.853507e+07</td>\n      <td>167.836714</td>\n      <td>3.840799</td>\n      <td>NaN</td>\n      <td>75.537477</td>\n      <td>241.702576</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9998</td>\n      <td>26.797447</td>\n      <td>288358.4</td>\n      <td>1.094471</td>\n      <td>0.505019</td>\n      <td>253.278224</td>\n      <td>19.199080</td>\n      <td>-4.451117</td>\n      <td>5.994078e+11</td>\n      <td>-3.025228e+05</td>\n      <td>...</td>\n      <td>101045.903091</td>\n      <td>225.324419</td>\n      <td>0.0</td>\n      <td>7.009934e+08</td>\n      <td>27.189454</td>\n      <td>0.538561</td>\n      <td>NaN</td>\n      <td>-10.481948</td>\n      <td>113.104089</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>9999</td>\n      <td>63.908598</td>\n      <td>288358.4</td>\n      <td>NaN</td>\n      <td>0.803881</td>\n      <td>234.035162</td>\n      <td>16.398958</td>\n      <td>-2.217535</td>\n      <td>4.389648e+11</td>\n      <td>8.104504e+05</td>\n      <td>...</td>\n      <td>78226.955793</td>\n      <td>157.853686</td>\n      <td>0.0</td>\n      <td>-8.710744e+07</td>\n      <td>252.716160</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-3.776887</td>\n      <td>101.844761</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 109 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 计算整个数据集的四分位数\n",
    "Q1 = train.iloc[:, 1:107].quantile(0.25)\n",
    "Q3 = train.iloc[:, 1:107].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 需要处理的label\n",
    "noisy_labels = [0, 1]\n",
    "\n",
    "for label in noisy_labels:\n",
    "    # 获取该label的数据\n",
    "    df_label = train[train['label'] == label].copy()\n",
    "\n",
    "    # 对每一列特征分别进行处理\n",
    "    for col in df_label.columns[1:107]:\n",
    "        # 将离群值设为NaN\n",
    "        df_label.loc[(df_label[col] < Q1[col] - 1.5 * IQR[col]) | (df_label[col] > Q3[col] + 1.5 * IQR[col]), col] = np.nan\n",
    "\n",
    "    # 更新原始数据\n",
    "    train.loc[train['label'] == label] = df_label\n",
    "\n",
    "# 你可以选择用KNN imputer或其他方法处理NaN值，或者直接删除含有NaN的行\n",
    "# df.dropna(inplace=True)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这是第二种四分位判别法，基于整个数据集来确定离群值的阈值，然后在各自的label中（例如label==0和label==1）应用这些阈值。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 需要处理的label\n",
    "noisy_labels = [0, 1]\n",
    "\n",
    "for label in noisy_labels:\n",
    "    # 获取该label的数据\n",
    "    df_label = train[train['label'] == label].copy()\n",
    "\n",
    "    # 对每一列特征分别进行处理\n",
    "    for col in df_label.columns[1:107]:\n",
    "        Q1 = df_label[col].quantile(0.25)\n",
    "        Q3 = df_label[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # 将离群值设为NaN\n",
    "        df_label.loc[(df_label[col] < Q1 - 1.5 * IQR) | (df_label[col] > Q3 + 1.5 * IQR), col] = np.nan\n",
    "\n",
    "    # 更新原始数据\n",
    "    train.loc[train['label'] == label] = df_label\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "以上两种方法只能采用其中一种，但是我并不确定哪种比较好。建议最后两种都试试，看看谁在验证集跑的分高。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN插值算法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "      sample_id   feature0  feature1  feature2  feature3    feature4  \\\n0             0  51.567250  288358.4  1.106507  1.855900  201.460169   \n1             1  63.804874  288358.4  1.106802  1.050387  391.605375   \n2             2  49.138527  288358.4  1.111649  0.767127  130.708067   \n3             3  64.411529  288358.4  1.109169  2.580881  258.521076   \n4             4  76.520831  288358.4  1.113410  5.795408  256.038997   \n...         ...        ...       ...       ...       ...         ...   \n9995       9995  66.948837  288358.4  1.102805 -0.310484  260.805938   \n9996       9996  41.137296  288358.4  1.107632  0.679847  160.449641   \n9997       9997  42.208350  288358.4  1.110253  0.037611  180.875482   \n9998       9998  26.797447  288358.4  1.094471  0.505019  253.278224   \n9999       9999  63.908598  288358.4  1.103880  0.803881  234.035162   \n\n       feature5   feature6      feature7      feature8  ...      feature98  \\\n0      6.582261  -0.516321  5.636771e+11  2.222212e+05  ...   31459.628135   \n1     13.323439   4.662871  1.089855e+11 -1.442474e+05  ...   42830.526855   \n2      6.485547   5.696815  5.474603e+11 -4.288403e+05  ...  249963.241809   \n3      0.716737  23.238461 -3.539891e+11  6.907655e+05  ...  125478.297201   \n4     -1.803483  14.040495 -1.071014e+11  6.499723e+05  ...  186266.423019   \n...         ...        ...           ...           ...  ...            ...   \n9995   6.663322  -6.495112 -1.959797e+11 -1.169449e+06  ...  131837.380427   \n9996  22.327405   2.251901  8.157356e+11  1.887989e+05  ...    3416.075865   \n9997   9.471924   6.725166  1.039534e+12  8.453963e+04  ...  149650.953476   \n9998  19.199080  -4.451117  5.994078e+11 -3.025228e+05  ...  101045.903091   \n9999  16.398958  -2.217535  4.389648e+11  8.104504e+05  ...   78226.955793   \n\n       feature99  feature100    feature101  feature102  feature103  \\\n0     254.582034         0.0 -2.014506e+08  159.299350    0.603211   \n1     270.580779         0.0 -1.534970e+09  163.755351    0.506220   \n2     160.207067         0.0  7.998345e+08  112.632639    0.080100   \n3     196.223295         0.0 -9.246920e+07  138.431470    2.548783   \n4     179.083883         0.0 -6.796351e+08  259.858740    0.337643   \n...          ...         ...           ...         ...         ...   \n9995  207.050530         0.0 -5.375408e+08  148.080110    1.598658   \n9996  228.252191         0.0  4.302888e+08  131.923443    2.348464   \n9997  211.716051         0.0 -5.853507e+07  167.836714    3.840799   \n9998  225.324419         0.0  7.009934e+08   27.189454    0.538561   \n9999  157.853686         0.0 -8.710744e+07  252.716160    0.298783   \n\n      feature104  feature105  feature106  label  \n0       0.387657   -5.256075  180.977310      4  \n1       0.552654   16.505952  314.783263      5  \n2       0.235920   64.707581  183.304610      2  \n3       1.414810   -9.662399  212.302670      2  \n4       0.228832   59.733069  135.541233      2  \n...          ...         ...         ...    ...  \n9995    1.239977   -1.625234         NaN      0  \n9996    3.079268   11.018358  250.312228      0  \n9997    0.834373   75.537477  241.702576      2  \n9998    2.199572  -10.481948  113.104089      0  \n9999    1.789714   -3.776887  101.844761      0  \n\n[10000 rows x 109 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>feature0</th>\n      <th>feature1</th>\n      <th>feature2</th>\n      <th>feature3</th>\n      <th>feature4</th>\n      <th>feature5</th>\n      <th>feature6</th>\n      <th>feature7</th>\n      <th>feature8</th>\n      <th>...</th>\n      <th>feature98</th>\n      <th>feature99</th>\n      <th>feature100</th>\n      <th>feature101</th>\n      <th>feature102</th>\n      <th>feature103</th>\n      <th>feature104</th>\n      <th>feature105</th>\n      <th>feature106</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>51.567250</td>\n      <td>288358.4</td>\n      <td>1.106507</td>\n      <td>1.855900</td>\n      <td>201.460169</td>\n      <td>6.582261</td>\n      <td>-0.516321</td>\n      <td>5.636771e+11</td>\n      <td>2.222212e+05</td>\n      <td>...</td>\n      <td>31459.628135</td>\n      <td>254.582034</td>\n      <td>0.0</td>\n      <td>-2.014506e+08</td>\n      <td>159.299350</td>\n      <td>0.603211</td>\n      <td>0.387657</td>\n      <td>-5.256075</td>\n      <td>180.977310</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>63.804874</td>\n      <td>288358.4</td>\n      <td>1.106802</td>\n      <td>1.050387</td>\n      <td>391.605375</td>\n      <td>13.323439</td>\n      <td>4.662871</td>\n      <td>1.089855e+11</td>\n      <td>-1.442474e+05</td>\n      <td>...</td>\n      <td>42830.526855</td>\n      <td>270.580779</td>\n      <td>0.0</td>\n      <td>-1.534970e+09</td>\n      <td>163.755351</td>\n      <td>0.506220</td>\n      <td>0.552654</td>\n      <td>16.505952</td>\n      <td>314.783263</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>49.138527</td>\n      <td>288358.4</td>\n      <td>1.111649</td>\n      <td>0.767127</td>\n      <td>130.708067</td>\n      <td>6.485547</td>\n      <td>5.696815</td>\n      <td>5.474603e+11</td>\n      <td>-4.288403e+05</td>\n      <td>...</td>\n      <td>249963.241809</td>\n      <td>160.207067</td>\n      <td>0.0</td>\n      <td>7.998345e+08</td>\n      <td>112.632639</td>\n      <td>0.080100</td>\n      <td>0.235920</td>\n      <td>64.707581</td>\n      <td>183.304610</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>64.411529</td>\n      <td>288358.4</td>\n      <td>1.109169</td>\n      <td>2.580881</td>\n      <td>258.521076</td>\n      <td>0.716737</td>\n      <td>23.238461</td>\n      <td>-3.539891e+11</td>\n      <td>6.907655e+05</td>\n      <td>...</td>\n      <td>125478.297201</td>\n      <td>196.223295</td>\n      <td>0.0</td>\n      <td>-9.246920e+07</td>\n      <td>138.431470</td>\n      <td>2.548783</td>\n      <td>1.414810</td>\n      <td>-9.662399</td>\n      <td>212.302670</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>76.520831</td>\n      <td>288358.4</td>\n      <td>1.113410</td>\n      <td>5.795408</td>\n      <td>256.038997</td>\n      <td>-1.803483</td>\n      <td>14.040495</td>\n      <td>-1.071014e+11</td>\n      <td>6.499723e+05</td>\n      <td>...</td>\n      <td>186266.423019</td>\n      <td>179.083883</td>\n      <td>0.0</td>\n      <td>-6.796351e+08</td>\n      <td>259.858740</td>\n      <td>0.337643</td>\n      <td>0.228832</td>\n      <td>59.733069</td>\n      <td>135.541233</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9995</td>\n      <td>66.948837</td>\n      <td>288358.4</td>\n      <td>1.102805</td>\n      <td>-0.310484</td>\n      <td>260.805938</td>\n      <td>6.663322</td>\n      <td>-6.495112</td>\n      <td>-1.959797e+11</td>\n      <td>-1.169449e+06</td>\n      <td>...</td>\n      <td>131837.380427</td>\n      <td>207.050530</td>\n      <td>0.0</td>\n      <td>-5.375408e+08</td>\n      <td>148.080110</td>\n      <td>1.598658</td>\n      <td>1.239977</td>\n      <td>-1.625234</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9996</td>\n      <td>41.137296</td>\n      <td>288358.4</td>\n      <td>1.107632</td>\n      <td>0.679847</td>\n      <td>160.449641</td>\n      <td>22.327405</td>\n      <td>2.251901</td>\n      <td>8.157356e+11</td>\n      <td>1.887989e+05</td>\n      <td>...</td>\n      <td>3416.075865</td>\n      <td>228.252191</td>\n      <td>0.0</td>\n      <td>4.302888e+08</td>\n      <td>131.923443</td>\n      <td>2.348464</td>\n      <td>3.079268</td>\n      <td>11.018358</td>\n      <td>250.312228</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9997</td>\n      <td>42.208350</td>\n      <td>288358.4</td>\n      <td>1.110253</td>\n      <td>0.037611</td>\n      <td>180.875482</td>\n      <td>9.471924</td>\n      <td>6.725166</td>\n      <td>1.039534e+12</td>\n      <td>8.453963e+04</td>\n      <td>...</td>\n      <td>149650.953476</td>\n      <td>211.716051</td>\n      <td>0.0</td>\n      <td>-5.853507e+07</td>\n      <td>167.836714</td>\n      <td>3.840799</td>\n      <td>0.834373</td>\n      <td>75.537477</td>\n      <td>241.702576</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9998</td>\n      <td>26.797447</td>\n      <td>288358.4</td>\n      <td>1.094471</td>\n      <td>0.505019</td>\n      <td>253.278224</td>\n      <td>19.199080</td>\n      <td>-4.451117</td>\n      <td>5.994078e+11</td>\n      <td>-3.025228e+05</td>\n      <td>...</td>\n      <td>101045.903091</td>\n      <td>225.324419</td>\n      <td>0.0</td>\n      <td>7.009934e+08</td>\n      <td>27.189454</td>\n      <td>0.538561</td>\n      <td>2.199572</td>\n      <td>-10.481948</td>\n      <td>113.104089</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>9999</td>\n      <td>63.908598</td>\n      <td>288358.4</td>\n      <td>1.103880</td>\n      <td>0.803881</td>\n      <td>234.035162</td>\n      <td>16.398958</td>\n      <td>-2.217535</td>\n      <td>4.389648e+11</td>\n      <td>8.104504e+05</td>\n      <td>...</td>\n      <td>78226.955793</td>\n      <td>157.853686</td>\n      <td>0.0</td>\n      <td>-8.710744e+07</td>\n      <td>252.716160</td>\n      <td>0.298783</td>\n      <td>1.789714</td>\n      <td>-3.776887</td>\n      <td>101.844761</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 109 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# 获取所有的label\n",
    "labels = train['label'].unique()\n",
    "\n",
    "# 对于每一个label，分别进行插值\n",
    "for label in labels:\n",
    "    # 获取该label的数据\n",
    "    df_label = train[train['label'] == label]\n",
    "\n",
    "    # 取出feature列\n",
    "    features = df_label.iloc[:,1:107]\n",
    "\n",
    "    # 创建KNN imputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    # 对feature进行插值\n",
    "    features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "    # 更新原始数据\n",
    "    train.loc[train['label'] == label, train.columns[1:107]] = features_imputed\n",
    "\n",
    "# 最后，train就是插值后的数据\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 对这些特征进行Anova方差分析，提取有效的50个特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}