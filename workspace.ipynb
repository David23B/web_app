{"cells":[{"cell_type":"code","execution_count":null,"id":"S6Rw3t0jCMe_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2353,"status":"ok","timestamp":1687504448812,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"S6Rw3t0jCMe_","outputId":"40fe62d0-e6d4-4868-deb1-646aae6cdbce"},"outputs":[],"source":["# 查看工作路径\n","import os\n","\n","print(os.getcwd())\n","\n","\n","# 修改工作路径\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/MyDrive/ML\"\n","os.chdir(path)\n","print(os.getcwd())"]},{"attachments":{},"cell_type":"markdown","id":"c1137df4","metadata":{"id":"c1137df4"},"source":["首先要对数据进行预处理。\n","这里先求出每个故障类型、每个特征的平均值，然后用这个平均值填入源文件。"]},{"cell_type":"code","execution_count":null,"id":"3a496a8c","metadata":{"executionInfo":{"elapsed":20661,"status":"ok","timestamp":1687504477369,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"3a496a8c"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# 加载数据\n","df = pd.read_csv('./train_10000.csv')\n","\n","# 处理缺失值\n","for label in range(6):\n","    for feature in range(107):\n","        feature_name = f'feature{feature}'\n","        mean_value = df[df['label'] == label][feature_name].mean()\n","        df.loc[(df['label'] == label) & (df[feature_name].isnull()), feature_name] = mean_value\n","\n","# 保存处理后的文件\n","df.to_csv('./train_10000_filled.csv', index=False)\n","\n","# 分割数据集\n","train, validation_and_test = train_test_split(df, test_size=0.3, random_state=42)\n","validation, test = train_test_split(validation_and_test, test_size=0.5, random_state=42)\n","\n","# 保存分割后的数据集\n","train.to_csv('./train_set.csv', index=False)\n","validation.to_csv('./validation_set.csv', index=False)\n","test.to_csv('./test_set.csv', index=False)\n"]},{"attachments":{},"cell_type":"markdown","id":"b166351b","metadata":{"id":"b166351b"},"source":["然后用随机森林，对每一个故障类型求出不同的特征对其重要性。"]},{"cell_type":"code","execution_count":null,"id":"f659c2b7","metadata":{"executionInfo":{"elapsed":98275,"status":"ok","timestamp":1687504579455,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"f659c2b7"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import StratifiedKFold\n","import numpy as np\n","\n","# 初始一个空的DataFrame用于存储所有故障类型的特征重要性\n","df = pd.read_csv('./train_10000_filled.csv')\n","\n","# 获取特征和标签\n","X = df.iloc[:, 1:-1]  # 取feature0到feature106作为特征\n","y = df['label']  # 取'label'列作为标签\n","\n","all_importances = pd.DataFrame(index=X.columns)\n","\n","# 使用分层K折交叉验证\n","skf = StratifiedKFold(n_splits=5)\n","\n","for fault_type in range(6):\n","    # 对于每个故障类型，我们将该类型标记为1，其他类型标记为0\n","    y_binary = (y == fault_type).astype(int)\n","\n","    feature_importances = []\n","\n","    for train_index, test_index in skf.split(X, y_binary):\n","        # 训练随机森林分类器\n","        clf = RandomForestClassifier(n_estimators=100, random_state=0, max_depth=5, min_samples_split=10)\n","        clf.fit(X.iloc[train_index], y_binary.iloc[train_index])\n","\n","        # 获取并存储特征重要性\n","        feature_importances.append(clf.feature_importances_)\n","\n","    # 通过所有交叉验证的平均值获取特征重要性\n","    all_importances[f'FaultType {fault_type}'] = np.mean(feature_importances, axis=0)\n","\n","# 保存特征重要性到CSV文件\n","all_importances.to_csv('./all_feature_importances.csv')\n","\n"]},{"attachments":{},"cell_type":"markdown","id":"ff19401e","metadata":{"id":"ff19401e"},"source":["创建热力图，看的更直观哪些特征影响力大"]},{"cell_type":"code","execution_count":null,"id":"c3beab11","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2334,"status":"ok","timestamp":1687504581786,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"c3beab11","outputId":"365144ef-c4c5-43ca-91e3-962b5992261b"},"outputs":[],"source":["# 创建热力图\n","plt.figure(figsize=(10, 20))\n","sns.heatmap(all_importances, cmap='Blues')\n","plt.title('Feature Importance for Each Fault Type')\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","id":"35fd06dd","metadata":{"id":"35fd06dd"},"source":["下面开始构建模型，首先选出影响力大的所有特征"]},{"cell_type":"code","execution_count":null,"id":"df388388","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687504581787,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"df388388","outputId":"d3db2525-911e-43d5-e40a-53cf6f2f16d9"},"outputs":[],"source":["all_importances = pd.read_csv('./all_feature_importances.csv', index_col=0)\n","# 为每个故障类型选择前6个最重要的特征\n","important_features_per_fault = {}\n","for fault_type in all_importances.columns:\n","    top_6_features = all_importances[fault_type].sort_values(ascending=False)[:6]\n","    important_features_per_fault[fault_type] = list(top_6_features.index)\n","\n","\n","# 打印结果\n","for fault_type, features in important_features_per_fault.items():\n","    print(f\"For {fault_type}, the most important features are {features}\")\n","\n","# 合并所有的重要特征到一个集合\n","selected_features = set()\n","\n","for features in important_features_per_fault.values():\n","    selected_features.update(features)\n","\n","print(\"最终选择的特征有：\",selected_features)"]},{"attachments":{},"cell_type":"markdown","id":"5b3215c2","metadata":{"id":"5b3215c2"},"source":["然后开始构建模型训练"]},{"cell_type":"code","execution_count":null,"id":"f706c121","metadata":{"id":"f706c121"},"outputs":[],"source":["import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import StandardScaler\n","\n","# 加载数据\n","df_train = pd.read_csv('./train_set.csv')\n","df_val = pd.read_csv('./validation_set.csv')\n","df_test = pd.read_csv('./test_set.csv')\n","\n","# 选择重要的特征\n","X_train = df_train[selected_features].values\n","y_train = df_train['label'].values\n","X_val = df_val[selected_features].values\n","y_val = df_val['label'].values\n","X_test = df_test[selected_features].values\n","y_test = df_test['label'].values\n","\n","# 标准化数据\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","X_test = scaler.transform(X_test)\n","\n","# 创建数据加载器\n","train_loader = DataLoader(TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train)), batch_size=32, shuffle=True)\n","val_loader = DataLoader(TensorDataset(torch.Tensor(X_val), torch.Tensor(y_val)), batch_size=32)\n","test_loader = DataLoader(TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test)), batch_size=32)\n","\n","# 创建模型\n","model = nn.Sequential(\n","    nn.Linear(len(selected_features), 64),\n","    nn.ReLU(),\n","    nn.Linear(64, 64),\n","    nn.ReLU(),\n","    nn.Linear(64, 6),\n",")\n","\n","# 定义损失函数和优化器\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.005)\n","\n","# 训练模型\n","for epoch in range(500):\n","    for X, y in train_loader:\n","        # 前向传播\n","        outputs = model(X)\n","        loss = criterion(outputs, y.long())\n","\n","        # 反向传播\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 在验证集上检查性能\n","    with torch.no_grad():\n","        val_loss = sum(criterion(model(X), y.long()) for X, y in val_loader)\n","    print(f\"Epoch {epoch + 1}, Validation Loss: {val_loss.item()}\")\n","\n","# 在测试集上检查性能\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","# 计算准确率和F1分值\n","def calculate_metrics(loader):\n","    all_preds = []\n","    all_true = []\n","\n","    with torch.no_grad():\n","        for X, y in loader:\n","            outputs = model(X)\n","            _, predicted = torch.max(outputs, 1)\n","            all_preds.extend(predicted.numpy())\n","            all_true.extend(y.numpy())\n","\n","    acc = accuracy_score(all_true, all_preds)\n","    f1 = f1_score(all_true, all_preds, average='macro')\n","\n","    return acc, f1"]},{"cell_type":"code","execution_count":null,"id":"KNEM4VkCJegL","metadata":{"executionInfo":{"elapsed":384,"status":"ok","timestamp":1687504996881,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"KNEM4VkCJegL"},"outputs":[],"source":["import pickle #调用“腌制”库\n","model_filename = './ufo-model.pkl'#设定文件名\n","pickle.dump(model, open(model_filename,'wb'))#对模型进行“腌制”"]},{"cell_type":"code","execution_count":null,"id":"AJmulQq5KDww","metadata":{"executionInfo":{"elapsed":389,"status":"ok","timestamp":1687504998942,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"AJmulQq5KDww"},"outputs":[],"source":["test_model = pickle.load(open('ufo-model.pkl','rb'))#加载“腌制”好的模型"]},{"cell_type":"code","execution_count":null,"id":"HmO5Af9yIWHC","metadata":{"id":"HmO5Af9yIWHC"},"outputs":[],"source":["for x in X_train[:10]:\n","  print(x)\n","  outputs = test_model(torch.tensor(x).to(torch.float32))\n","  _, pre = torch.max(outputs, 0)\n","  print(pre.item())"]},{"cell_type":"code","execution_count":null,"id":"t1DO8EpoFrRU","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1687488294672,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"t1DO8EpoFrRU","outputId":"9884a211-ec5a-4d0b-8949-5fb63b704040"},"outputs":[],"source":["torch.save(model.state_dict(), './save.pt')\n","\n","mymodel = nn.Sequential(\n","    nn.Linear(len(selected_features), 64),\n","    nn.ReLU(),\n","    nn.Linear(64, 64),\n","    nn.ReLU(),\n","    nn.Linear(64, 6),\n",")\n","\n","mymodel.load_state_dict(torch.load('./save.pt'))\n","mymodel.eval()"]},{"cell_type":"code","execution_count":null,"id":"a1dac756","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1038,"status":"ok","timestamp":1687488685342,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"a1dac756","outputId":"7a964d9f-8b93-4351-ef5a-d808f5b16fa6"},"outputs":[],"source":["# 计算准确率和F1分值\n","def calculate_metrics(loader):\n","    all_preds = []\n","    all_true = []\n","\n","    with torch.no_grad():\n","        for X, y in loader:\n","            outputs = test_model(X)\n","            _, predicted = torch.max(outputs, 1)\n","            all_preds.extend(predicted.numpy())\n","            all_true.extend(y.numpy())\n","\n","    acc = accuracy_score(all_true, all_preds)\n","    f1 = f1_score(all_true, all_preds, average='macro')\n","\n","    return acc, f1\n","\n","# 在训练集、验证集和测试集上计算准确率和F1分值\n","train_acc, train_f1 = calculate_metrics(train_loader)\n","val_acc, val_f1 = calculate_metrics(val_loader)\n","test_acc, test_f1 = calculate_metrics(test_loader)\n","\n","print(f\"Training Accuracy: {train_acc}, Training F1 Score: {train_f1}\")\n","print(f\"Validation Accuracy: {val_acc}, Validation F1 Score: {val_f1}\")\n","print(f\"Test Accuracy: {test_acc}, Test F1 Score: {test_f1}\")"]},{"cell_type":"code","execution_count":null,"id":"464e1f96","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":872},"executionInfo":{"elapsed":570,"status":"ok","timestamp":1687487131301,"user":{"displayName":"Jinbiao Lai","userId":"03193972943227304794"},"user_tz":-480},"id":"464e1f96","outputId":"4ca79736-9f2c-4d2d-9fdb-f999dbe0b8aa"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","# 计算预测值\n","y_test_pred = []\n","with torch.no_grad():\n","    for X, _ in test_loader:\n","        outputs = model(X)\n","        _, predicted = torch.max(outputs, 1)\n","        y_test_pred.extend(predicted.numpy())\n","\n","# 计算混淆矩阵\n","cm = confusion_matrix(y_test, y_test_pred)\n","\n","# 绘制混淆矩阵\n","plt.figure(figsize=(10, 10))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","id":"f27b9c69","metadata":{"id":"f27b9c69"},"source":["我们发现对故障类型1和2的预测不够好。第一个思路就是看看是不是还有特征对1和2影响较大，尝试把它们加入进我们的训练特征集中。\n","然后试过之后发现没卵用(╯▔皿▔)╯\n","但是我发现在原数据集中，出现0型故障的最多，超过了总数的一半。所以这是一个数据集不平衡的问题。我们可能要采用过采样的方法。\n","## 总结\n","    1.在数据预处理的时候，根据每一种故障类型的平均值进行填缺，可能不够科学？\n","    2.数据集不平衡\n","    3.如何更好的预测1，2类型的故障\n","    4.如何提高F1的分值，现在的分还是太低了"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}
